#!/usr/bin/env python3
"""
Debug script to analyze model outputs and cursor generation.

This script examines the actual values being generated by the model
and how they're being processed by the sampling functions.
"""

import torch
import numpy as np
import yaml
from pathlib import Path
from src.models.transformer import OsuTransformer
from src.config.model_config import ModelConfig
from src.generation.generator import ReplayGenerator
from src.generation.sampling import CursorSampling

def analyze_model_outputs():
    """Analyze what the model is actually outputting."""
    print("=== Model Output Analysis ===")
    print()
    
    # Load config
    config_path = Path("config/default.yaml")
    with open(config_path, 'r') as f:
        config_dict = yaml.safe_load(f)
    
    config = ModelConfig(**config_dict['model'])
    
    # Create model
    model = OsuTransformer(config)
    model.eval()
    
    # Create dummy inputs
    seq_len = 10
    batch_size = 1
    
    cursor_data = torch.randn(seq_len, batch_size, 2)
    beatmap_data = torch.randn(seq_len, batch_size, 8)
    slider_data = torch.randn(seq_len, batch_size, 13)
    timing_data = torch.randn(seq_len, batch_size, 1)
    key_data = torch.randn(seq_len, batch_size, 4)
    accuracy_target = torch.tensor([[0.95]]).float()  # Ensure float type
    
    print(f"Input shapes:")
    print(f"  cursor_data: {cursor_data.shape}")
    print(f"  beatmap_data: {beatmap_data.shape}")
    print(f"  slider_data: {slider_data.shape}")
    print(f"  timing_data: {timing_data.shape}")
    print(f"  key_data: {key_data.shape}")
    print(f"  accuracy_target: {accuracy_target.shape}")
    print()
    
    # Forward pass
    with torch.no_grad():
        outputs = model(
            cursor_data=cursor_data,
            beatmap_data=beatmap_data,
            slider_data=slider_data,
            timing_data=timing_data,
            key_data=key_data,
            accuracy_target=accuracy_target
        )
    
    cursor_pred = outputs['cursor_pred']
    key_pred = outputs['key_pred']
    
    print(f"Output shapes:")
    print(f"  cursor_pred: {cursor_pred.shape}")
    print(f"  key_pred: {key_pred.shape}")
    print()
    
    print(f"Cursor prediction statistics:")
    print(f"  Min: {cursor_pred.min().item():.4f}")
    print(f"  Max: {cursor_pred.max().item():.4f}")
    print(f"  Mean: {cursor_pred.mean().item():.4f}")
    print(f"  Std: {cursor_pred.std().item():.4f}")
    print()
    
    print(f"Sample cursor predictions (last timestep):")
    last_cursor_pred = cursor_pred[-1, 0, :]  # [2]
    print(f"  Raw logits: [{last_cursor_pred[0].item():.4f}, {last_cursor_pred[1].item():.4f}]")
    
    # Test cursor sampling
    cursor_sampler = CursorSampling()
    
    # Test with no previous position
    sampled_pos_1 = cursor_sampler.sample(last_cursor_pred.unsqueeze(0))
    print(f"  Sampled (no prev): [{sampled_pos_1[0, 0].item():.1f}, {sampled_pos_1[0, 1].item():.1f}]")
    
    # Test with previous position
    prev_pos = torch.tensor([[256.0, 192.0]])  # Center of screen
    sampled_pos_2 = cursor_sampler.sample(last_cursor_pred.unsqueeze(0), prev_pos)
    print(f"  Sampled (with prev): [{sampled_pos_2[0, 0].item():.1f}, {sampled_pos_2[0, 1].item():.1f}]")
    
    # Calculate movement
    movement = torch.norm(sampled_pos_2 - prev_pos).item()
    print(f"  Movement distance: {movement:.1f} pixels")
    print()
    
    # Test with extreme logits
    print("Testing with extreme logits:")
    extreme_logits = torch.tensor([[5.0, -5.0]])  # Very high and very low
    sampled_extreme = cursor_sampler.sample(extreme_logits, prev_pos)
    extreme_movement = torch.norm(sampled_extreme - prev_pos).item()
    print(f"  Extreme logits: [5.0, -5.0]")
    print(f"  Sampled: [{sampled_extreme[0, 0].item():.1f}, {sampled_extreme[0, 1].item():.1f}]")
    print(f"  Movement: {extreme_movement:.1f} pixels")
    print()
    
    # Analyze tanh transformation
    print("Analyzing tanh transformation:")
    test_logits = torch.tensor([[-3.0, -1.0, 0.0, 1.0, 3.0]])
    tanh_values = torch.tanh(test_logits)
    screen_coords = (tanh_values + 1) * 256  # For x-coordinate (512/2)
    
    print(f"  Logits: {test_logits[0].tolist()}")
    print(f"  Tanh: {tanh_values[0].tolist()}")
    print(f"  Screen coords: {screen_coords[0].tolist()}")
    print()
    
    print("=== Analysis Summary ===")
    print("The model outputs raw logits that are passed through tanh to get [-1, 1] range,")
    print("then scaled to screen coordinates. The issue might be:")
    print("1. Model outputs are too small (close to 0)")
    print("2. Movement limiting in CursorSampling is too restrictive")
    print("3. Model hasn't learned to generate diverse cursor movements")
    print()
    print("The movement limiting was already increased from 10% to 50% of screen.")
    print("If movement is still limited, the model itself might need retraining")
    print("or the logits might need scaling.")

def test_cursor_sampling_variations():
    """Test different cursor sampling configurations."""
    print("\n=== Testing Cursor Sampling Variations ===")
    print()
    
    # Test logits
    cursor_logits = torch.tensor([[1.0, -0.5]])  # Moderate logits
    prev_pos = torch.tensor([[256.0, 192.0]])  # Center
    
    print(f"Test logits: {cursor_logits[0].tolist()}")
    print(f"Previous position: {prev_pos[0].tolist()}")
    print()
    
    # Test different smoothness weights
    smoothness_values = [0.0, 0.1, 0.5, 1.0]
    
    for smoothness in smoothness_values:
        sampler = CursorSampling(smoothness_weight=smoothness)
        sampled_pos = sampler.sample(cursor_logits, prev_pos)
        movement = torch.norm(sampled_pos - prev_pos).item()
        
        print(f"Smoothness {smoothness:.1f}: pos=[{sampled_pos[0, 0].item():.1f}, {sampled_pos[0, 1].item():.1f}], movement={movement:.1f}px")
    
    print()
    print("Lower smoothness_weight allows more movement.")
    print("If movement is still too limited, the issue is likely in the model outputs.")

if __name__ == "__main__":
    try:
        analyze_model_outputs()
        test_cursor_sampling_variations()
    except Exception as e:
        print(f"Error during analysis: {e}")
        import traceback
        traceback.print_exc()